{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "RNN.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XBsfQDpc9Un",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re, torch, time\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.utils.data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U55XbJOXc9VB",
        "colab_type": "code",
        "outputId": "19ac45ee-37d6-450a-adc4-f6632f24b638",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eTVZFV8deDE",
        "colab_type": "code",
        "outputId": "4f6370e9-7b65-432c-d7bd-ee5ef87f1f50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgcKn7dwc9VX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_pickle(\"/content/drive/My Drive/Colab Notebooks/INF8111/data/preprocess_2classes.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66Fm78Q-8IM8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07f76c76-ab16-4bb9-ecc2-e2c4d1e01022"
      },
      "source": [
        "pos_weight = len(data.loc[data[\"label\"]==0]) / len(data.loc[data[\"label\"]==1])\n",
        "print(pos_weight)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21.472016895459344\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCn_iC3cc9Vr",
        "colab_type": "code",
        "outputId": "d5b04639-ebae-49ca-92b9-a85eea90d330",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "plt.hist([len(x) for x in data.tweet], bins=30)\n",
        "plt.title(\"Sequence length distribution\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Sequence length distribution')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEICAYAAABF82P+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgJY4N4Ic9V2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_max = 50000\n",
        "seq_length = 30\n",
        "count_words = Counter()\n",
        "for tweet in data.tweet:\n",
        "    for tok in tweet:\n",
        "        count_words[tok] +=1\n",
        "vocab = {w for w,_ in count_words.most_common(vocab_max-2)}.union( {\"UNK\", \"PAD\"})\n",
        "word2val = {w : i+2 for i, (w,_) in enumerate( count_words.most_common(vocab_max-2) )}\n",
        "word2val[\"PAD\"] = 0\n",
        "word2val[\"UNK\"] = 1\n",
        "X = []\n",
        "for tweet in data.tweet:\n",
        "    tmp = [word2val[tok] if tok in vocab else word2val[\"UNK\"] for tok in tweet]\n",
        "    if len(tmp) > seq_length:\n",
        "        X.append(tmp[:seq_length])\n",
        "    else:\n",
        "        X.append([0 for _ in range(seq_length - len(tmp))] + tmp)\n",
        "X = np.array(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQFW2Y4vc9WF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, np.array(data.label), test_size=0.33, random_state=42)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.5, random_state=42)\n",
        "X_train = torch.tensor(X_train)\n",
        "X_valid = torch.tensor(X_valid)\n",
        "X_test = torch.tensor(X_test)\n",
        "y_train = torch.tensor(y_train)\n",
        "y_valid = torch.tensor(y_valid)\n",
        "y_test = torch.tensor(y_test)\n",
        "train_data = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "valid_data = torch.utils.data.TensorDataset(X_valid, y_valid)\n",
        "test_data = torch.utils.data.TensorDataset(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP_e5_Gqnrzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MafDXaTqTyU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_accuracy(model, data_loader):\n",
        "  correct = 0\n",
        "  for i, (X_batch, y_batch) in enumerate(data_loader):\n",
        "    torch.cuda.empty_cache()\n",
        "    X_batch = X_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "    out = model.forward(X_batch.to(device))\n",
        "    correct += (torch.max(out, 1)[1] == y_batch).float().sum()\n",
        "  return((100*correct/len(test_loader.dataset)).item())\n",
        "  \n",
        "def compute_scores(model, data_loader):\n",
        "  y_hat = []\n",
        "  y = []\n",
        "  for i, (X_batch, y_batch) in enumerate(data_loader):\n",
        "    torch.cuda.empty_cache()\n",
        "    X_batch = X_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "    out = model.forward(X_batch.to(device))\n",
        "    out = (torch.sigmoid(out) > 0.5).float() \n",
        "    y_hat = y_hat + out.squeeze().tolist()\n",
        "    y = y + y_batch.tolist()\n",
        "  prec = metrics.precision_score(y, y_hat)\n",
        "  recall = metrics.recall_score(y, y_hat)\n",
        "  f1 = metrics.f1_score(y, y_hat)\n",
        "  return prec, recall, f1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UV-k6sFc9WP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 emb_size,\n",
        "                 hidden_size,\n",
        "                 vocab_size,\n",
        "                 num_layers,\n",
        "                 nonlinearity = 'relu',\n",
        "                 bias = True,\n",
        "                 dropout = 0,\n",
        "                 bidirectional = True\n",
        "                ):\n",
        "        super(RNN, self).__init__()\n",
        "        #hyper-parameters\n",
        "        self.emb_size      = emb_size\n",
        "        self.hidden_size   = hidden_size\n",
        "        self.vocab_size    = vocab_size\n",
        "        self.num_layers    = num_layers\n",
        "        self.nonlinearity  = nonlinearity\n",
        "        self.bias          = bias\n",
        "        self.dropout       = dropout\n",
        "        self.bidirectional = bidirectional\n",
        "        #layers\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size).to(device)\n",
        "        self.rnn = nn.GRU(input_size = emb_size,\n",
        "                          hidden_size = hidden_size,\n",
        "                          num_layers = num_layers,\n",
        "                          bias = bias,\n",
        "                          dropout = dropout,\n",
        "                          bidirectional = bidirectional\n",
        "                         ).to(device)\n",
        "        self.linear = nn.Linear((bidirectional+1) *hidden_size, 1).to(device)\n",
        "        \n",
        "    def forward(self, X):\n",
        "        out = self.embedding(X.t())\n",
        "        out, _ = self.rnn(out)\n",
        "        return self.linear(out[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM20Y5YCc9WV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn = RNN( emb_size = 512,\n",
        "         hidden_size = 512,\n",
        "         vocab_size = vocab_max,\n",
        "         num_layers = 4,\n",
        "         nonlinearity = 'tanh',\n",
        "         dropout = 0.5,\n",
        "         bidirectional=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6CnMqxdc9Wf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# criterion = nn.CrossEntropyLoss(weight=torch.tensor(weight_balance).to(device))\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight).to(device))\n",
        "optimizer = torch.optim.Adam(rnn.parameters(),weight_decay=10e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uIpsgumc9Ww",
        "colab_type": "code",
        "outputId": "ca87e21a-0bd7-4377-e0bb-71f74b94aef0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        }
      },
      "source": [
        "n_epochs = 10\n",
        "start_time = time.time()\n",
        "last_time = time.time()\n",
        "for epoch in range(1, n_epochs+1):\n",
        "    print(\"Epoch: {}/{}\".format(epoch, n_epochs))\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    for i, (X_batch, y_batch) in enumerate(train_loader):\n",
        "        torch.cuda.empty_cache()\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = rnn.forward(X_batch.to(device))\n",
        "        loss = criterion(out.squeeze(), y_batch.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        correct += (torch.max(out, 1)[1] == y_batch).float().sum()\n",
        "        # if time.time() - last_time > 0.5:\n",
        "        #     print(\"Samples:{}/{}\\tloss: {:.4f}\\tacc: {:2.3f}\\telapsed_time: {:.1f}s\"\\\n",
        "        #           .format( (i+1)*batch_size, len(train_loader.dataset),\\\n",
        "        #                   running_loss/((i+1)*batch_size), 100*correct/((i+1)*batch_size), time.time()-start_time), end='\\r')\n",
        "        #     last_time = time.time()\n",
        "    prec, recall, f1 = compute_scores(rnn, valid_loader)\n",
        "    print(\"Samples:{}/{}\\tloss: {:.4f}\\tacc: {:2.3f}\\telapsed_time: {:.1f}s\\tvalid_acc: {:2.3f}\\tprec: {}\\trecall: {}\\tf1: {}\"\\\n",
        "          .format( (i+1)*batch_size, len(train_loader.dataset),\\\n",
        "                  running_loss/((i+1)*batch_size), 100*correct/((i+1)*batch_size), time.time()-start_time,\n",
        "                  compute_accuracy(rnn, valid_loader), prec, recall, f1), flush=True)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/10\n",
            "Samples:57056/57033\tloss: 0.0343\tacc: 95.517\telapsed_time: 128.7s\tvalid_acc: 95.493\tprec: 0.23703703703703705\trecall: 0.35443037974683544\tf1: 0.2840837032339886\n",
            "Epoch: 2/10\n",
            "Samples:57056/57033\tloss: 0.0316\tacc: 95.517\telapsed_time: 267.7s\tvalid_acc: 95.493\tprec: 0.11248785228377065\trecall: 0.7325949367088608\tf1: 0.19502948609941026\n",
            "Epoch: 3/10\n",
            "Samples:57056/57033\tloss: 0.0306\tacc: 95.517\telapsed_time: 406.8s\tvalid_acc: 95.493\tprec: 0.15421245421245422\trecall: 0.6661392405063291\tf1: 0.25044616299821537\n",
            "Epoch: 4/10\n",
            "Samples:57056/57033\tloss: 0.0295\tacc: 95.517\telapsed_time: 545.7s\tvalid_acc: 95.493\tprec: 0.132873425314937\trecall: 0.7009493670886076\tf1: 0.22339889056984366\n",
            "Epoch: 5/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-66560327c103>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DNvNRyCNClg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_scores(model, data_loader):\n",
        "  y_hat = []\n",
        "  y = []\n",
        "  for i, (X_batch, y_batch) in enumerate(data_loader):\n",
        "    torch.cuda.empty_cache()\n",
        "    X_batch = X_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "    out = model.forward(X_batch.to(device))\n",
        "    out = (torch.sigmoid(out) > 0.5).float() \n",
        "    y_hat = y_hat + out.squeeze().tolist()\n",
        "    y = y + y_batch.tolist()\n",
        "  prec = metrics.precision_score(y, y_hat)\n",
        "  recall = metrics.recall_score(y, y_hat)\n",
        "  f1 = metrics.f1_score(y, y_hat)\n",
        "  return prec, recall, f1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Us7hlK7dUsEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}