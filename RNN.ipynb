{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, torch\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"data/preprocess_balanced.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Sequence length distribution')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(x) for x in data.tweet], bins=30)\n",
    "plt.title(\"Sequence length distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_max = 50000\n",
    "seq_length = 30\n",
    "count_words = Counter()\n",
    "for tweet in data.tweet:\n",
    "    for tok in tweet:\n",
    "        count_words[tok] +=1\n",
    "vocab = {w for w,_ in count_words.most_common(vocab_max-2)}.union( {\"UNK\", \"PAD\"})\n",
    "word2val = {w : i+2 for i, (w,_) in enumerate( count_words.most_common(vocab_max-2) )}\n",
    "word2val[\"PAD\"] = 0\n",
    "word2val[\"UNK\"] = 1\n",
    "X = []\n",
    "for tweet in data.tweet:\n",
    "    tmp = [word2val[tok] if tok in vocab else word2val[\"UNK\"] for tok in tweet]\n",
    "    if len(tmp) > seq_length:\n",
    "        X.append(tmp[:seq_length])\n",
    "    else:\n",
    "        X.append([0 for _ in range(seq_length - len(tmp))] + tmp)\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, np.array(data.label), test_size=0.33, random_state=42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.5, random_state=42)\n",
    "X_train = torch.tensor(X_train).to(device)\n",
    "X_valid = torch.tensor(X_valid).to(device)\n",
    "X_test = torch.tensor(X_test).to(device)\n",
    "y_train = torch.tensor(y_train).to(device)\n",
    "y_valid = torch.tensor(y_valid).to(device)\n",
    "y_test = torch.tensor(y_test).to(device)\n",
    "train_data = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "valid_data = torch.utils.data.TensorDataset(X_valid, y_valid)\n",
    "test_data = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size,\n",
    "                 hidden_size,\n",
    "                 vocab_size,\n",
    "                 num_layers,\n",
    "                 output_size,\n",
    "                 nonlinearity = 'relu',\n",
    "                 bias = True,\n",
    "                 dropout = 0,\n",
    "                 bidirectional = False\n",
    "                ):\n",
    "        super(RNN, self).__init__()\n",
    "        #hyper-parameters\n",
    "        self.emb_size      = emb_size\n",
    "        self.hidden_size   = hidden_size\n",
    "        self.vocab_size    = vocab_size\n",
    "        self.num_layers    = num_layers\n",
    "        self.output_size   = output_size\n",
    "        self.nonlinearity  = nonlinearity\n",
    "        self.bias          = bias\n",
    "        self.dropout       = dropout\n",
    "        self.bidirectional = bidirectional\n",
    "        #layers\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size).to(device)\n",
    "        self.rnn = nn.RNN(input_size = emb_size,\n",
    "                          hidden_size = hidden_size,\n",
    "                          num_layers = num_layers,\n",
    "                          bias = bias,\n",
    "                          dropout = dropout,\n",
    "                          bidirectional = bidirectional\n",
    "                         )\n",
    "        self.linear = nn.Linear((bidirectional+1) *hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = self.embedding(X.t())\n",
    "        out, _ = self.rnn(out)\n",
    "        out = self.linear(out[-1])\n",
    "        return nn.functional.softmax(out, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN( emb_size = 100,\n",
    "         hidden_size = 100,\n",
    "         vocab_size = vocab_max,\n",
    "         num_layers = 1,\n",
    "         output_size = 4,\n",
    "         bidirectional=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5\n",
      "\n",
      "Epoch: 2/5050/10151\tloss: 0.0235\tacc: 0.565\n",
      "\n",
      "Samples:4050/10151\tloss: 0.0236\tacc: 0.556\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-0d1df9d5b394>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    print(\"Epoch: {}/{}\\n\".format(epoch, n_epochs))\n",
    "    optimizer.zero_grad()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    for i, (X_batch, y_batch) in enumerate(train_loader):\n",
    "        out = rnn.forward(X_batch)\n",
    "        loss = criterion(out, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        correct += (torch.max(out, 1)[1] == y_batch).float().sum()\n",
    "        if i%10 == 0:\n",
    "            print(\"Samples:{}/{}\\tloss: {:.4f}\\tacc: {:2.3f}\"\\\n",
    "                  .format( (i+1)*batch_size, len(train_loader.dataset),\\\n",
    "                          running_loss/((i+1)*batch_size), correct/((i+1)*batch_size) ), end='\\r', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4274)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rnn(X_test[:]).max(dim=1)[1] == y_test[:]).float().sum()/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
