{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "RNN.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XBsfQDpc9Un",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re, torch, time\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.utils.data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U55XbJOXc9VB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4a746d3-0b9f-4927-f043-88d082112661"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eTVZFV8deDE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9db8e72-4f56-4556-a43b-0e16b4eff63f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgcKn7dwc9VX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_pickle(\"/content/drive/My Drive/Colab Notebooks/INF8111/data/preprocess_balanced.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCn_iC3cc9Vr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "9948244b-4a82-482b-a082-87c0716a92bd"
      },
      "source": [
        "plt.hist([len(x) for x in data.tweet], bins=30)\n",
        "plt.title(\"Sequence length distribution\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Sequence length distribution')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqSOGviR1xNCXpI78f1PaNc74EqGLAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgJY4N4Ic9V2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_max = 50000\n",
        "seq_length = 30\n",
        "count_words = Counter()\n",
        "for tweet in data.tweet:\n",
        "    for tok in tweet:\n",
        "        count_words[tok] +=1\n",
        "vocab = {w for w,_ in count_words.most_common(vocab_max-2)}.union( {\"UNK\", \"PAD\"})\n",
        "word2val = {w : i+2 for i, (w,_) in enumerate( count_words.most_common(vocab_max-2) )}\n",
        "word2val[\"PAD\"] = 0\n",
        "word2val[\"UNK\"] = 1\n",
        "X = []\n",
        "for tweet in data.tweet:\n",
        "    tmp = [word2val[tok] if tok in vocab else word2val[\"UNK\"] for tok in tweet]\n",
        "    if len(tmp) > seq_length:\n",
        "        X.append(tmp[:seq_length])\n",
        "    else:\n",
        "        X.append([0 for _ in range(seq_length - len(tmp))] + tmp)\n",
        "X = np.array(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQFW2Y4vc9WF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, np.array(data.label), test_size=0.33, random_state=42)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.5, random_state=42)\n",
        "X_train = torch.tensor(X_train)\n",
        "X_valid = torch.tensor(X_valid)\n",
        "X_test = torch.tensor(X_test)\n",
        "y_train = torch.tensor(y_train)\n",
        "y_valid = torch.tensor(y_valid)\n",
        "y_test = torch.tensor(y_test)\n",
        "train_data = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "valid_data = torch.utils.data.TensorDataset(X_valid, y_valid)\n",
        "test_data = torch.utils.data.TensorDataset(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP_e5_Gqnrzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UV-k6sFc9WP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 emb_size,\n",
        "                 hidden_size,\n",
        "                 vocab_size,\n",
        "                 num_layers,\n",
        "                 output_size,\n",
        "                 nonlinearity = 'relu',\n",
        "                 bias = True,\n",
        "                 dropout = 0,\n",
        "                 bidirectional = True\n",
        "                ):\n",
        "        super(RNN, self).__init__()\n",
        "        #hyper-parameters\n",
        "        self.emb_size      = emb_size\n",
        "        self.hidden_size   = hidden_size\n",
        "        self.vocab_size    = vocab_size\n",
        "        self.num_layers    = num_layers\n",
        "        self.output_size   = output_size\n",
        "        self.nonlinearity  = nonlinearity\n",
        "        self.bias          = bias\n",
        "        self.dropout       = dropout\n",
        "        self.bidirectional = bidirectional\n",
        "        #layers\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size).to(device)\n",
        "        self.rnn = nn.GRU(input_size = emb_size,\n",
        "                          hidden_size = hidden_size,\n",
        "                          num_layers = num_layers,\n",
        "                          bias = bias,\n",
        "                          dropout = dropout,\n",
        "                          bidirectional = bidirectional\n",
        "                         ).to(device)\n",
        "        self.linear = nn.Linear((bidirectional+1) *hidden_size, output_size).to(device)\n",
        "        \n",
        "    def forward(self, X):\n",
        "        out = self.embedding(X.t())\n",
        "        out, _ = self.rnn(out)\n",
        "        return self.linear(out[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM20Y5YCc9WV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn = RNN( emb_size = 1024,\n",
        "         hidden_size = 512,\n",
        "         vocab_size = vocab_max,\n",
        "         num_layers = 3,\n",
        "         output_size = 4,\n",
        "         bidirectional=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6CnMqxdc9Wf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(rnn.parameters(),weight_decay=10e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uIpsgumc9Ww",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "f4752ed6-f7e6-4830-9029-1386e94bf17c"
      },
      "source": [
        "n_epochs = 5\n",
        "start_time = time.time()\n",
        "last_time = time.time()\n",
        "for epoch in range(1, n_epochs+1):\n",
        "    print(\"Epoch: {}/{}\".format(epoch, n_epochs))\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    for i, (X_batch, y_batch) in enumerate(train_loader):\n",
        "        torch.cuda.empty_cache()\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = rnn.forward(X_batch.to(device))\n",
        "        loss = criterion(out, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        correct += (torch.max(out, 1)[1] == y_batch).float().sum()\n",
        "        if time.time() - last_time > 0.5:\n",
        "            print(\"Samples:{}/{}\\tloss: {:.4f}\\tacc: {:2.3f}\\telapsed_time: {:.1f}s\"\\\n",
        "                  .format( (i+1)*batch_size, len(train_loader.dataset),\\\n",
        "                          running_loss/((i+1)*batch_size), 100*correct/((i+1)*batch_size), time.time()-start_time), end='\\r')\n",
        "            last_time = time.time()\n",
        "    print(\"Samples:{}/{}\\tloss: {:.4f}\\tacc: {:2.3f}\\telapsed_time: {:.1f}s\\tvalid_acc: {:2.3f}\"\\\n",
        "          .format( (i+1)*batch_size, len(train_loader.dataset),\\\n",
        "                  running_loss/((i+1)*batch_size), 100*correct/((i+1)*batch_size), time.time()-start_time,\n",
        "                  100*(rnn(X_valid.to(device)).max(dim=1)[1] == y_valid.to(device)).float().sum()/len(y_valid.to(device))), flush=True)\n",
        "    print(\"test_acc : {:2.3f}\".format(100*(rnn(X_test.to(device)).max(dim=1)[1] == y_test.to(device)).float().sum()/len(y_test)))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/5\n",
            "Samples:10176/10151\tloss: 0.0103\tacc: 72.474\telapsed_time: 33.3s\tvalid_acc: 68.720\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-1a06e17cc7ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     print(\"Samples:{}/{}\\tloss: {:.4f}\\tacc: {:2.3f}\\telapsed_time: {:.1f}s\\tvalid_acc: {:2.3f}\"          .format( (i+1)*batch_size, len(train_loader.dataset),                  running_loss/((i+1)*batch_size), 100*correct/((i+1)*batch_size), time.time()-start_time,\n\u001b[1;32m     23\u001b[0m                   100*(rnn(X_valid.to(device)).max(dim=1)[1] == y_valid.to(device)).float().sum()/len(y_valid.to(device))), flush=True)\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_acc : {:2.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-7b5d781dbe29>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0msorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mrun_impl\u001b[0;34m(self, input, hx, batch_sizes)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             result = _VF.gru(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[0;32m--> 680\u001b[0;31m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    681\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m             result = _VF.gru(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 5.72 GiB (GPU 0; 11.17 GiB total capacity; 4.67 GiB already allocated; 2.29 GiB free; 3.89 GiB cached)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDzHh0hlNwkB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b354331e-f9a8-46b4-b343-92f52c6e1c33"
      },
      "source": [
        "correct = 0\n",
        "for i, (X_batch, y_batch) in enumerate(test_loader):\n",
        "  torch.cuda.empty_cache()\n",
        "  X_batch = X_batch.to(device)\n",
        "  y_batch = y_batch.to(device)\n",
        "  out = rnn.forward(X_batch.to(device))\n",
        "  correct += (torch.max(out, 1)[1] == y_batch).float().sum()\n",
        "print(100*correct/len(test_loader.dataset))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(68.2927, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtcBXhJ9OapD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed041400-baed-4086-f22a-da111ca1ac47"
      },
      "source": [
        "len(test_loader.dataset)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2501"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FrTNiWlOcCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}