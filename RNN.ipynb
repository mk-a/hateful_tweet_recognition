{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, string, nltk, torch\n",
    "from nltk.tokenize import word_tokenize\n",
    "import words_repeated_char\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file_path, delimiter = ' '):\n",
    "    \"\"\" We had some issues loading the data using pandas.read_csv, so we built our own loader.\n",
    "        Read a csv file, returns a pandas.Dataframe\n",
    "    \"\"\"\n",
    "    fp = open(file_path)\n",
    "    line = fp.readline()\n",
    "    data_dict = dict()\n",
    "    labels = line[:-1].split(delimiter)\n",
    "    line = fp.readline()\n",
    "    for label in labels:\n",
    "        data_dict[label] = []\n",
    "    while line:\n",
    "        for i, j in enumerate(line[:-1].split(delimiter)):\n",
    "            data_dict[labels[i]].append(j)\n",
    "        line = fp.readline()\n",
    "    return pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_csv(\"data/hydrated/hateful_tweets_filtered.csv\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7629505483</td>\n",
       "      <td>abusive</td>\n",
       "      <td>I fuckin hate when niggas stare at me fuck r u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12181574836</td>\n",
       "      <td>abusive</td>\n",
       "      <td>everyone jumps to silly conclusions as soon as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25381445793</td>\n",
       "      <td>abusive</td>\n",
       "      <td>#sincewerebeinghonest I'm Emo. I Need A Fuckin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192730077165916160</td>\n",
       "      <td>abusive</td>\n",
       "      <td>banana bread recipe: 1. get some bread 2. i do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>280882735374028800</td>\n",
       "      <td>abusive</td>\n",
       "      <td>godamn this bitch so bad i want 2 drink molly ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id    label  \\\n",
       "0          7629505483  abusive   \n",
       "1         12181574836  abusive   \n",
       "2         25381445793  abusive   \n",
       "3  192730077165916160  abusive   \n",
       "4  280882735374028800  abusive   \n",
       "\n",
       "                                       tweet_content  \n",
       "0  I fuckin hate when niggas stare at me fuck r u...  \n",
       "1  everyone jumps to silly conclusions as soon as...  \n",
       "2  #sincewerebeinghonest I'm Emo. I Need A Fuckin...  \n",
       "3  banana bread recipe: 1. get some bread 2. i do...  \n",
       "4  godamn this bitch so bad i want 2 drink molly ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer() \n",
    "preprocessed = []\n",
    "count_words = Counter()\n",
    "for i, tweet in enumerate(data[\"tweet_content\"].values[:]):\n",
    "    tmp = tweet.lower().replace(\"\\\\n\",' ').replace('\\\\xa0', ' ').replace('\\\\r', ' ').replace(\"\\\\'\",\"'\").replace(\"&lt;\",'<')\\\n",
    "         .replace(\"&gt;\",'>').replace(\" &amp; \", \" and \").replace(\"&amp;\", \"&\")\n",
    "    # lower the tweet and replacing characters that tweeter has tranlated to their hmtl numeric code to their original value\n",
    "    tmp = re.sub(\"(http(s)?://)?(www\\.)?([a-zA-Z0-9])+\\.[a-z]{1,3}(/\\S*)?\",'URL', tmp) # \n",
    "    tmp = re.sub(\"#\\w+\", 'HASHTAG', tmp)\n",
    "    tmp = re.sub(\"@\\w+\", 'USER', tmp)\n",
    "    tmp = re.sub(\"\\w+@\\w+\\.[a-z]{2,3}\", \"EMAIL\", tmp)\n",
    "    tmp = re.sub(\"[0-9]{1,2}/[0-9]{1,2}/([0-9]{4}|[0-9]{2})|([0-9]{4}|[0-9]{2})/[0-9]{1,2}/[0-9]{1,2}|[0-9]{2}/[0-9]{2}\", \"DATE\", tmp)\n",
    "    tmp = re.sub(\"[0-9]{2}(:[0-9]{2}){1,2}( ?(am|pm))?\", \"TIME\", tmp)\n",
    "    tmp = re.sub(\"(([\\U00002600-\\U000027BF])|([\\U0001f300-\\U0001f64F])|([\\U0001f680-\\U0001f6FF]))+\", ' EMOJI ', tmp)\n",
    "    tmp = tmp.encode(encoding='ascii', errors='ignore').decode()\n",
    "    # get rid of the non ascii characters\n",
    "    tmp = re.sub(\"\\.{2,}\", \"...\", tmp)\n",
    "    for c in ['!', '-', ',']:\n",
    "        tmp = re.sub(\"{}+\".format(c), c, tmp)\n",
    "    tmp = re.sub(\"\\?+\", \"?\", tmp)\n",
    "    tmp = re.sub(\"`+\", \"'\", tmp)\n",
    "    tmp = re.sub(\"'{2,}\", \"'\", tmp)\n",
    "    tmp = tmp.translate(str.maketrans(dict.fromkeys('#*+/<=>@[\\\\]^_`{|}~'))) #removing all the other special characters\n",
    "    tokens = [t if t not in [\"''\", \"``\"] else '\"' for t in word_tokenize(tmp) ]\n",
    "    # tokenizing using nltk.word_tokenize. althought it transforms '\"' into '``' or \"''\" and this is a behaviour do not want\n",
    "    # so we make sure that the '\"' are changed to their original form\n",
    "    vec = []\n",
    "    for i, token in enumerate(tokens):\n",
    "        if re.search(r\"([a-z])\\1{2,}\", token):\n",
    "            # cleaning the words containing a letter repeated 3 times or more, using the list of the Ensglish words\n",
    "            tokens[i] = words_repeated_char.clean(token)\n",
    "        tokens[i] = lemmatizer.lemmatize(tokens[i])\n",
    "        count_words[tokens[i]] += 1\n",
    "    preprocessed.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_max = 50000\n",
    "seq_length = 30\n",
    "vocab = {w for w,_ in count_words.most_common(vocab_max-2)}.union( {\"UNK\", \"PAD\"})\n",
    "word2val = {w : i+2 for i, (w,_) in enumerate( count_words.most_common(vocab_max-2) )}\n",
    "word2val[\"PAD\"] = 0\n",
    "word2val[\"UNK\"] = 1\n",
    "X = []\n",
    "for tweet in preprocessed:\n",
    "    tmp = [word2val[tok] if tok in vocab else word2val[\"UNK\"] for tok in tweet]\n",
    "    if len(tmp) > seq_length:\n",
    "        X.append(tmp[:seq_length])\n",
    "    else:\n",
    "        X.append([0 for _ in range(seq_length - len(tmp))] + tmp)\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(data[\"label\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Sequence length distribution')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEICAYAAAC0+DhzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGqhJREFUeJzt3Xu0XWV97vHvQ0IwXBNkc0sCQUmVy5CLORCrKIUaEvQQhkoL9TSBxhPlYI+eYUcFT1tA4AzoaItliNgUIkGRQFFKVDCmCMdiIbApEQgBswFLtglkYxLkUuEAv/PH/O12st+1s9a+roQ8nzHW2HP+3nfO9b57JetZa8659lJEYGZmVrdDuwdgZmZbH4eDmZkVHA5mZlZwOJiZWcHhYGZmBYeDmZkVHA62XZIUkg5uw/0eL6l7CNtfIOlbuXyApBcljRmmsX1d0p8Pxzgb7Ps4SY8P1/5s5DkctmOSPiDpXyQ9L2mjpJ9K+i/tHtdbyUiGUEQ8HRG7RsTrTcZwpqS7W9jfZyLiouEYW995R8Q/R8S7hmPfNjrGtnsA1h6Sdge+D5wN3ASMA44DXmnnuKw9JI1pFjK2ffE7h+3XbwFExA0R8XpE/HtE/CgiHurtIOmPJK2WtEnSMkkH1to+LOmxfNfxVUn/V9Knsu0/Dn3k+tR8JTk21/eQdI2k9ZJ+Keni3kMjva9yJf1V3u9TkmbX9rWnpG9IWpft/1hr+6iklZI25zui97Tyi5C0U97f05KezcMr47PteEndkr4gaUOO+azatm+X9D1Jv5Z0f87l7mz7SXb7WR7++f3adg3312BsB+Xv9gVJy4G9tvB7PVPSk9n3KUmflHQI8HXgfTmGzdn3WklXSbpN0kvA72Tt4j73/yVJz0n6haRP1up39T7e9cetv3n3PUwl6ZDcx2ZJqySdUmu7VtKVkn6Qc1kh6Z3NHkcbXg6H7dfPgdclLZY0W9LEeqOkU4EvAR8DOoB/Bm7Itr2A7wB/RvVk9QTw/gHc92LgNeBg4ChgJvCpWvuxwOO5778ErpGkbPsmsDNwGLA3cHmO6WhgEfBp4O3A3wFLJe3UwnguowrLI3NMk4C/qLXvC+yR9fnAlbXf15XAS9lnXt4AiIgP5uIRefjnxhb219e3gQfyd3FRff91knYBrgBmR8RuwG8DKyNiNfAZ4J4cw4TaZn8AXALsBjQ67LRv3u+kvN+FkpoeGtrCvHvHuiPwPeBHVI/hHwPX99n3GcCFwESgK8dpoykifNtOb8AhwLVAN9WT9VJgn2y7HZhf67sD8DJwIDAXuLfWptzHp3L9AuBbtfapQFAdxtyH6tDV+Fr7GcCduXwm0FVr2zm33RfYD3gDmNhgLlcBF/WpPQ58qJ+5B1UQiOrJ/Z21tvcBT+Xy8cC/A2Nr7RuAGcAY4P8B76q1XQzc3fd+auv97q/BGA/Ix2WXWu3bvb/bPr/XXYDNwMfrv9va7/TuPrVrgesa1C6ujbPvfd8E/Hku39X7eDe6j37m3Z3LxwHPADvU2m8ALqiN4+pa28nAY+3+/7K93fzOYTsWEasj4syImAwcDuwPfCWbDwT+Nt/2bwY2Uj2RTsp+a2v7ifp6EwcCOwLra/v+O6pXkL2eqe375VzcFZgCbIyITf3s9wu9+8z9TsmxbkkHVQA9UNvuh1nv9auIeK22/nKOp4Pqibk+91Z+D/3tr6/9gU0R8VKt9m+Ndph9fp/qXcL6PCTz7ibjaDbWRvfd7PfZiv2BtRHxRp99T6qtP1Nb7u/3YyPI4WAARMRjVK/YDs/SWuDTETGhdhsfEf8CrKd64gUgD/lMqe3uJaon3F771pbXUr1z2Ku2390j4rAWhrkW2FPShH7aLukz3p0j4oYm+3yO6pX8YbXt9oiIVp6MeqheXU+u1ab003cw1gMT85BRrwP66xwRyyLiw1TvsB4D/r63qb9Nmtx/o/tel8tbeoybWQdMkVR//jkA+OUA9mEjzOGwnZL07jwpOjnXp1Ad3rk3u3wdOE/SYdm+h6TTsu0HwGGSPpYnQ/8nb35yWAl8UNV1+HsA5/U2RMR6qmPNfy1pd0k7SHqnpA81G3NuezvwNUkTJe0oqff49t8Dn5F0rCq7SPqIpN2a7PON3PZySXvnXCdJOqmF8bwOfBe4QNLO+Up9bp9uzwLvaLavfvb/b0AncKGkcZI+APzXRn0l7SPplHwyfwV4Eei9+uhZYLKkcYMYRu99Hwd8FPiHrK8EPpbzPpjq3Endlua9gipc/jQfw+NzXksGMT4bIQ6H7dcLVCd+V+TVKvcCjwBfAIiIW6hO1C6R9Otsm51tzwGnAZcCvwKmAT/t3XFELAduBB6iOpn6/T73PZfq0tlHgU3AzVSvdlvxh1TH+R+jOlb/+bzPTuC/A1/NfXZRHQdvxRez/705138CWr0m/7NUJ5efoTpZfgNvvhz4AmBxHrL6vRb3WfcHVI/TRuB84Lp++u1A9dity74fAv5Htv0YWAU8I+m5Adz3M1S/y3XA9cBn8h0mVBcCvEoVAouzve4C+pl3RLwKnEL17+k54GvA3Nq+bSug6nCx2dBIuovqROnV7R5LO0m6DNg3IhpeVWS2rfA7B7MhyMNz78lDWcdQHV65pd3jMhsqf0LabGh2ozqUtD/VYa6/Bm5t64jMhoEPK5mZWcGHlczMrLDNHlbaa6+9YurUqe0ehpnZNuOBBx54LiI6mvfchsNh6tSpdHZ2tnsYZmbbDEkNP2HfiA8rmZlZweFgZmYFh4OZmRUcDmZmVnA4mJlZweFgZmYFh4OZmRVaCgdJEyTdrOoL5VdLep+qL3pfLmlN/pyYfSXpCkldkh7K7/bt3c+87L9G0rxa/b2SHs5trqh9X7CZmbVBq+8c/hb4YUS8GzgCWA2cC9wREdOAO3Idqr/RPi1vC6i+2xdJe1L9PfpjgWOA82tfqn5V9u3dbtbQpmVmZkPR9BPSknYHPkh+cUp+UcerkuZQfWk4VF/2cRfVl6bMofri8qD68pQJkvbLvssjYmPudzkwK78HYPeIuCfr1wGnUn3jl9k2Z+q5P2jL/f7i0o+05X7tramVdw7voPqu3G9IelDS1flVhPvk1zb2fn1j7xfET+LNX1zenbUt1bsb1AuSFkjqlNTZ09PTwtDNzGwwWgmHscDRwFURcRTVd7+eu4X+jc4XxCDqZTFiYURMj4jpHR0t/e0oMzMbhFbCoRvojogVuX4zVVg8m4eLyJ8bav2n1LafTPUdtFuqT25QNzOzNmkaDhHxDLBWUu8Xrp9I9cXwS4HeK47m8Z/ffrUUmJtXLc0Ans/DTsuAmZIm5onomcCybHtB0oy8Smku/iYtM7O2avVPdv8xcL2kccCTwFlUwXKTpPnA08Bp2fc24GSgC3g5+xIRGyVdBNyf/b7ce3IaOBu4FhhPdSLaJ6PNzNqopXCIiJXA9AZNJzboG8A5/exnEbCoQb0TOLyVsZiZ2cjzJ6TNzKzgcDAzs4LDwczMCg4HMzMrOBzMzKzgcDAzs4LDwczMCg4HMzMrOBzMzKzgcDAzs4LDwczMCg4HMzMrOBzMzKzgcDAzs4LDwczMCg4HMzMrOBzMzKzgcDAzs4LDwczMCg4HMzMrOBzMzKzgcDAzs4LDwczMCg4HMzMrOBzMzKzQUjhI+oWkhyWtlNSZtT0lLZe0Jn9OzLokXSGpS9JDko6u7Wde9l8jaV6t/t7cf1duq+GeqJmZtW4g7xx+JyKOjIjpuX4ucEdETAPuyHWA2cC0vC0AroIqTIDzgWOBY4DzewMl+yyobTdr0DMyM7MhG8phpTnA4lxeDJxaq18XlXuBCZL2A04ClkfExojYBCwHZmXb7hFxT0QEcF1tX2Zm1gathkMAP5L0gKQFWdsnItYD5M+9sz4JWFvbtjtrW6p3N6gXJC2Q1Cmps6enp8Whm5nZQI1tsd/7I2KdpL2B5ZIe20LfRucLYhD1shixEFgIMH369IZ9zMxs6Fp65xAR6/LnBuAWqnMGz+YhIfLnhuzeDUypbT4ZWNekPrlB3czM2qRpOEjaRdJuvcvATOARYCnQe8XRPODWXF4KzM2rlmYAz+dhp2XATEkT80T0TGBZtr0gaUZepTS3ti8zM2uDVg4r7QPckleXjgW+HRE/lHQ/cJOk+cDTwGnZ/zbgZKALeBk4CyAiNkq6CLg/+305Ijbm8tnAtcB44Pa8mZlZmzQNh4h4EjiiQf1XwIkN6gGc08++FgGLGtQ7gcNbGK+ZmY0Cf0LazMwKDgczMys4HMzMrOBwMDOzgsPBzMwKDgczMys4HMzMrOBwMDOzgsPBzMwKDgczMys4HMzMrOBwMDOzgsPBzMwKDgczMys4HMzMrOBwMDOzgsPBzMwKDgczMys4HMzMrOBwMDOzgsPBzMwKDgczMys4HMzMrOBwMDOzgsPBzMwKLYeDpDGSHpT0/Vw/SNIKSWsk3ShpXNZ3yvWubJ9a28d5WX9c0km1+qysdUk6d/imZ2ZmgzGQdw6fA1bX1i8DLo+IacAmYH7W5wObIuJg4PLsh6RDgdOBw4BZwNcycMYAVwKzgUOBM7KvmZm1SUvhIGky8BHg6lwXcAJwc3ZZDJyay3NynWw/MfvPAZZExCsR8RTQBRyTt66IeDIiXgWWZF8zM2uTVt85fAX4U+CNXH87sDkiXsv1bmBSLk8C1gJk+/PZ/z/qfbbpr25mZm3SNBwkfRTYEBEP1MsNukaTtoHWG41lgaROSZ09PT1bGLWZmQ1FK+8c3g+cIukXVId8TqB6JzFB0tjsMxlYl8vdwBSAbN8D2Fiv99mmv3ohIhZGxPSImN7R0dHC0M3MbDCahkNEnBcRkyNiKtUJ5R9HxCeBO4FPZLd5wK25vDTXyfYfR0Rk/fS8mukgYBpwH3A/MC2vfhqX97F0WGZnZmaDMrZ5l359EVgi6WLgQeCarF8DfFNSF9U7htMBImKVpJuAR4HXgHMi4nUASZ8FlgFjgEURsWoI4zIzsyEaUDhExF3AXbn8JNWVRn37/AY4rZ/tLwEuaVC/DbhtIGMxM7OR409Im5lZweFgZmYFh4OZmRUcDmZmVnA4mJlZweFgZmYFh4OZmRUcDmZmVnA4mJlZweFgZmYFh4OZmRUcDmZmVnA4mJlZweFgZmYFh4OZmRUcDmZmVnA4mJlZweFgZmYFh4OZmRUcDmZmVnA4mJlZweFgZmYFh4OZmRUcDmZmVnA4mJlZweFgZmaFpuEg6W2S7pP0M0mrJF2Y9YMkrZC0RtKNksZlfadc78r2qbV9nZf1xyWdVKvPylqXpHOHf5pmZjYQrbxzeAU4ISKOAI4EZkmaAVwGXB4R04BNwPzsPx/YFBEHA5dnPyQdCpwOHAbMAr4maYykMcCVwGzgUOCM7GtmZm3SNByi8mKu7pi3AE4Abs76YuDUXJ6T62T7iZKU9SUR8UpEPAV0AcfkrSsinoyIV4El2dfMzNqkpXMO+Qp/JbABWA48AWyOiNeySzcwKZcnAWsBsv154O31ep9t+qs3GscCSZ2SOnt6eloZupmZDUJL4RARr0fEkcBkqlf6hzTqlj/VT9tA643GsTAipkfE9I6OjuYDNzOzQRnQ1UoRsRm4C5gBTJA0NpsmA+tyuRuYApDtewAb6/U+2/RXNzOzNmnlaqUOSRNyeTzwu8Bq4E7gE9ltHnBrLi/NdbL9xxERWT89r2Y6CJgG3AfcD0zLq5/GUZ20XjockzMzs8EZ27wL+wGL86qiHYCbIuL7kh4Flki6GHgQuCb7XwN8U1IX1TuG0wEiYpWkm4BHgdeAcyLidQBJnwWWAWOARRGxathmaGZmA9Y0HCLiIeCoBvUnqc4/9K3/Bjitn31dAlzSoH4bcFsL4zUzs1HgT0ibmVnB4WBmZgWHg5mZFRwOZmZWcDiYmVnB4WBmZgWHg5mZFRwOZmZWcDiYmVnB4WBmZgWHg5mZFRwOZmZWcDiYmVnB4WBmZgWHg5mZFRwOZmZWcDiYmVnB4WBmZgWHg5mZFRwOZmZWcDiYmVnB4WBmZgWHg5mZFRwOZmZWcDiYmVmhaThImiLpTkmrJa2S9Lms7ylpuaQ1+XNi1iXpCkldkh6SdHRtX/Oy/xpJ82r190p6OLe5QpJGYrJmZtaaVt45vAZ8ISIOAWYA50g6FDgXuCMipgF35DrAbGBa3hYAV0EVJsD5wLHAMcD5vYGSfRbUtps19KmZmdlgNQ2HiFgfEf+ayy8Aq4FJwBxgcXZbDJyay3OA66JyLzBB0n7AScDyiNgYEZuA5cCsbNs9Iu6JiACuq+3LzMzaYEDnHCRNBY4CVgD7RMR6qAIE2Du7TQLW1jbrztqW6t0N6o3uf4GkTkmdPT09Axm6mZkNQMvhIGlX4DvA5yPi11vq2qAWg6iXxYiFETE9IqZ3dHQ0G7KZmQ1SS+EgaUeqYLg+Ir6b5WfzkBD5c0PWu4Eptc0nA+ua1Cc3qJuZWZu0crWSgGuA1RHxN7WmpUDvFUfzgFtr9bl51dIM4Pk87LQMmClpYp6Ingksy7YXJM3I+5pb25eZmbXB2Bb6vB/4Q+BhSSuz9iXgUuAmSfOBp4HTsu024GSgC3gZOAsgIjZKugi4P/t9OSI25vLZwLXAeOD2vJmZWZs0DYeIuJvG5wUATmzQP4Bz+tnXImBRg3oncHizsZiZ2ejwJ6TNzKzgcDAzs4LDwczMCg4HMzMrOBzMzKzgcDAzs4LDwczMCg4HMzMrOBzMzKzgcDAzs4LDwczMCg4HMzMrOBzMzKzgcDAzs4LDwczMCg4HMzMrOBzMzKzgcDAzs4LDwczMCg4HMzMrOBzMzKzgcDAzs4LDwczMCg4HMzMrOBzMzKzQNBwkLZK0QdIjtdqekpZLWpM/J2Zdkq6Q1CXpIUlH17aZl/3XSJpXq79X0sO5zRWSNNyTNDOzgWnlncO1wKw+tXOBOyJiGnBHrgPMBqblbQFwFVRhApwPHAscA5zfGyjZZ0Ftu773ZWZmo6xpOETET4CNfcpzgMW5vBg4tVa/Lir3AhMk7QecBCyPiI0RsQlYDszKtt0j4p6ICOC62r7MzKxNBnvOYZ+IWA+QP/fO+iRgba1fd9a2VO9uUG9I0gJJnZI6e3p6Bjl0MzNrZrhPSDc6XxCDqDcUEQsjYnpETO/o6BjkEM3MrJnBhsOzeUiI/Lkh693AlFq/ycC6JvXJDepmZtZGgw2HpUDvFUfzgFtr9bl51dIM4Pk87LQMmClpYp6Ingksy7YXJM3Iq5Tm1vZlZmZtMrZZB0k3AMcDe0nqprrq6FLgJknzgaeB07L7bcDJQBfwMnAWQERslHQRcH/2+3JE9J7kPpvqiqjxwO15MzOzNmoaDhFxRj9NJzboG8A5/exnEbCoQb0TOLzZOMzMbPT4E9JmZlZwOJiZWcHhYGZmBYeDmZkVHA5mZlZwOJiZWcHhYGZmBYeDmZkVHA5mZlZwOJiZWcHhYGZmBYeDmZkVHA5mZlZwOJiZWcHhYGZmBYeDmZkVHA5mZlZwOJiZWcHhYGZmBYeDmZkVHA5mZlZwOJiZWcHhYGZmBYeDmZkVHA5mZlZwOJiZWWGrCQdJsyQ9LqlL0rntHo+Z2fZsqwgHSWOAK4HZwKHAGZIObe+ozMy2X1tFOADHAF0R8WREvAosAea0eUxmZtutse0eQJoErK2tdwPH9u0kaQGwIFdflPT4KIxtOO0FPNfuQYwyz3mU6LLRvsc38eO8bTiw1Y5bSzioQS2KQsRCYOHID2dkSOqMiOntHsdo8py3D57zW8/WclipG5hSW58MrGvTWMzMtntbSzjcD0yTdJCkccDpwNI2j8nMbLu1VRxWiojXJH0WWAaMARZFxKo2D2skbLOHxIbAc94+eM5vMYooDu2bmdl2bms5rGRmZlsRh4OZmRUcDsNA0hRJd0paLWmVpM9l/QhJ90h6WNL3JO3ez/YTJN0s6bHcx/tGdwYDNwxz/l+53SOSbpD0ttGdwcBJepuk+yT9LMd+YdYPkrRC0hpJN+ZFFY22Py//PMzjkk4a3dEPzlDmLOnDkh7IfwsPSDph9GcwMEN9jLPvAZJelPQnozfyERARvg3xBuwHHJ3LuwE/p/ozIPcDH8r6HwEX9bP9YuBTuTwOmNDuOY3knKk+9PgUMD7XbwLObPecWpizgF1zeUdgBTAjx3961r8OnN1g20OBnwE7AQcBTwBj2j2nEZ7zUcD+uXw48Mt2z2ck51vbx3eAfwD+pN3zGcrN7xyGQUSsj4h/zeUXgNVUT4DvAn6S3ZYDH++7bb6y/iBwTW7/akRsHo1xD8VQ5pzGAuMljQV2Zhv4XEtUXszVHfMWwAnAzVlfDJzaYPM5wJKIeCUingK6qP5szFZtKHOOiAcjovdxXQW8TdJOIzzkIRniY4ykU4Enqea7TXM4DDNJU6leMa0AHgFOyabTePMH/Xq9A+gBviHpQUlXS9plFIY6bAY654j4JfBXwNPAeuD5iPjRaIx1qCSNkbQS2EAVfk8AmyPitezSTRWSfTX6EzGN+m11hjDnuo8DD0bEKyM30uEx2Pnm/9svAheO1lhHksNhGEnaleot5ecj4tdUh1XOkfQA1aGXVxtsNhY4GrgqIo4CXgK2mT9ZPpg5S5pI9Ur6IGB/YBdJ/230Rj14EfF6RBxJ9Sn+Y4BDGnVrUGvpT8RsjYYwZwAkHQZcBnx6ZEY4vIYw3wuBy2vvPLZpW8WH4N4KJO1I9SR5fUR8FyAiHgNmZvtvAR9psGk30B0RK3L9ZraRcBjCnH8XeCoierLfd4HfBr41GuMeDhGxWdJdVMejJ0gam68s+/vTL9v8n4gZxJyRNBm4BZgbEU+M2mCHwSDmeyzwCUl/CUwA3pD0m4j46qgNehj5ncMwkCSqcwarI+JvavW98+cOwJ9Rnch6k4h4Blgr6V1ZOhF4dMQHPURDmTPV4aQZknbO/ZxIdc5iqyapQ9KEXB5PFXKrgTuBT2S3ecCtDTZfCpwuaSdJBwHTgPtGftRDM5Q553Y/AM6LiJ+OzoiHZijzjYjjImJqREwFvgL8n201GABfrTQcN+ADVG8zHwJW5u1k4HNUV/H8HLiU//xE+v7AbbXtjwQ6c/t/BCa2e06jMOcLgceozlF8E9ip3XNqYc7vAR7MOT8C/EXW30H1RN9FdZXKTlk/Bfhybfv/TXX8+nFgdrvnM9Jzpnpx8FLt38dKYO92z2kkH+Pafi5gG79ayX8+w8zMCj6sZGZmBYeDmZkVHA5mZlZwOJiZWcHhYGZmBYeDmZkVHA5mZlb4/zWiI44loQI+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(x) for x in X])\n",
    "plt.title(\"Sequence length distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.5, random_state=42)\n",
    "X_train = torch.tensor(X_train).to(device)\n",
    "X_valid = torch.tensor(X_valid).to(device)\n",
    "X_test = torch.tensor(X_test).to(device)\n",
    "y_train = torch.tensor(y_train).to(device)\n",
    "y_valid = torch.tensor(y_valid).to(device)\n",
    "y_test = torch.tensor(y_test).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size,\n",
    "                 hidden_size,\n",
    "                 vocab_size,\n",
    "                 num_layers,\n",
    "                 output_size,\n",
    "                 nonlinearity = 'relu',\n",
    "                 bias = True,\n",
    "                 dropout = 0,\n",
    "                 bidirectional = False\n",
    "                ):\n",
    "        super(RNN, self).__init__()\n",
    "        #hyper-parameters\n",
    "        self.emb_size      = emb_size\n",
    "        self.hidden_size   = hidden_size\n",
    "        self.vocab_size    = vocab_size\n",
    "        self.num_layers    = num_layers\n",
    "        self.output_size   = output_size\n",
    "        self.nonlinearity  = nonlinearity\n",
    "        self.bias          = bias\n",
    "        self.dropout       = dropout\n",
    "        self.bidirectional = bidirectional\n",
    "        #layers\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size).to(device)\n",
    "        self.rnn = nn.RNN(input_size = emb_size,\n",
    "                          hidden_size = hidden_size,\n",
    "                          num_layers = num_layers,\n",
    "                          bias = bias,\n",
    "                          dropout = dropout,\n",
    "                          bidirectional = bidirectional\n",
    "                         )\n",
    "        self.linear = nn.Linear((bidirectional+1) *hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = self.embedding(X.t())\n",
    "        out, _ = self.rnn(out)\n",
    "        out = self.linear(out[-1])\n",
    "        return nn.functional.softmax(out, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = RNN( emb_size = 1000,\n",
    "         hidden_size = 1000,\n",
    "         vocab_size = vocab_max,\n",
    "         num_layers = 2,\n",
    "         output_size = 4,\n",
    "         bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2322, 0.1799, 0.2198, 0.3680],\n",
      "        [0.2153, 0.2844, 0.2357, 0.2646],\n",
      "        [0.2371, 0.1822, 0.2567, 0.3240],\n",
      "        [0.2127, 0.3254, 0.2445, 0.2174],\n",
      "        [0.1689, 0.3148, 0.2367, 0.2796],\n",
      "        [0.2192, 0.2202, 0.2361, 0.3244],\n",
      "        [0.2085, 0.3227, 0.2210, 0.2477],\n",
      "        [0.2971, 0.1978, 0.2086, 0.2965],\n",
      "        [0.2347, 0.2277, 0.2412, 0.2964],\n",
      "        [0.2381, 0.2207, 0.3311, 0.2101]], grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([10, 4])\n"
     ]
    }
   ],
   "source": [
    "b =a.forward(X_train[:10])\n",
    "print(b)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
