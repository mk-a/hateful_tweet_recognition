{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, torch, time\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"data/preprocess_balanced.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Sequence length distribution')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(x) for x in data.tweet], bins=30)\n",
    "plt.title(\"Sequence length distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_max = 50000\n",
    "seq_length = 30\n",
    "count_words = Counter()\n",
    "for tweet in data.tweet:\n",
    "    for tok in tweet:\n",
    "        count_words[tok] +=1\n",
    "vocab = {w for w,_ in count_words.most_common(vocab_max-2)}.union( {\"UNK\", \"PAD\"})\n",
    "word2val = {w : i+2 for i, (w,_) in enumerate( count_words.most_common(vocab_max-2) )}\n",
    "word2val[\"PAD\"] = 0\n",
    "word2val[\"UNK\"] = 1\n",
    "X = []\n",
    "for tweet in data.tweet:\n",
    "    tmp = [word2val[tok] if tok in vocab else word2val[\"UNK\"] for tok in tweet]\n",
    "    if len(tmp) > seq_length:\n",
    "        X.append(tmp[:seq_length])\n",
    "    else:\n",
    "        X.append([0 for _ in range(seq_length - len(tmp))] + tmp)\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, np.array(data.label), test_size=0.33, random_state=42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.5, random_state=42)\n",
    "X_train = torch.tensor(X_train).to(device)\n",
    "X_valid = torch.tensor(X_valid).to(device)\n",
    "X_test = torch.tensor(X_test).to(device)\n",
    "y_train = torch.tensor(y_train).to(device)\n",
    "y_valid = torch.tensor(y_valid).to(device)\n",
    "y_test = torch.tensor(y_test).to(device)\n",
    "train_data = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "valid_data = torch.utils.data.TensorDataset(X_valid, y_valid)\n",
    "test_data = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size,\n",
    "                 hidden_size,\n",
    "                 vocab_size,\n",
    "                 num_layers,\n",
    "                 output_size,\n",
    "                 nonlinearity = 'relu',\n",
    "                 bias = True,\n",
    "                 dropout = 0,\n",
    "                 bidirectional = False\n",
    "                ):\n",
    "        super(RNN, self).__init__()\n",
    "        #hyper-parameters\n",
    "        self.emb_size      = emb_size\n",
    "        self.hidden_size   = hidden_size\n",
    "        self.vocab_size    = vocab_size\n",
    "        self.num_layers    = num_layers\n",
    "        self.output_size   = output_size\n",
    "        self.nonlinearity  = nonlinearity\n",
    "        self.bias          = bias\n",
    "        self.dropout       = dropout\n",
    "        self.bidirectional = bidirectional\n",
    "        #layers\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size).to(device)\n",
    "        self.rnn = nn.RNN(input_size = emb_size,\n",
    "                          hidden_size = hidden_size,\n",
    "                          num_layers = num_layers,\n",
    "                          bias = bias,\n",
    "                          dropout = dropout,\n",
    "                          bidirectional = bidirectional\n",
    "                         )\n",
    "        self.linear = nn.Linear((bidirectional+1) *hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = self.embedding(X.t())\n",
    "        out, _ = self.rnn(out)\n",
    "#         out = self.linear(out[-1])\n",
    "        return self.linear(out[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN( emb_size = 4096,\n",
    "         hidden_size = 1024,\n",
    "         vocab_size = vocab_max,\n",
    "         num_layers = 2,\n",
    "         output_size = 4,\n",
    "         bidirectional=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20\n",
      "Samples:10200/10151\tloss: 0.0235\tacc: 46.343\telapsed_time: 384.7s\n",
      "Epoch: 2/20\n",
      "Samples:10200/10151\tloss: 0.0203\tacc: 53.667\telapsed_time: 778.9s\n",
      "Epoch: 3/20\n",
      "Samples:10200/10151\tloss: 0.0171\tacc: 63.186\telapsed_time: 1161.6s\n",
      "Epoch: 4/20\n",
      "Samples:10200/10151\tloss: 0.0158\tacc: 66.598\telapsed_time: 1537.1s\n",
      "Epoch: 5/20\n",
      "Samples:10200/10151\tloss: 0.0129\tacc: 74.549\telapsed_time: 1909.5s\n",
      "Epoch: 6/20\n",
      "Samples:10200/10151\tloss: 0.0117\tacc: 77.775\telapsed_time: 2278.7s\n",
      "Epoch: 7/20\n",
      "Samples:2250/10151\tloss: 0.0084\tacc: 84.889\telapsed_time: 2362.1s\r"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "start_time = time.time()\n",
    "last_time = time.time()\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    print(\"Epoch: {}/{}\".format(epoch, n_epochs))\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    for i, (X_batch, y_batch) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        out = rnn.forward(X_batch)\n",
    "        loss = criterion(out, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        correct += (torch.max(out, 1)[1] == y_batch).float().sum()\n",
    "        if time.time() - last_time > 0.5:\n",
    "            print(\"Samples:{}/{}\\tloss: {:.4f}\\tacc: {:2.3f}\\telapsed_time: {:.1f}s\"\\\n",
    "                  .format( (i+1)*batch_size, len(train_loader.dataset),\\\n",
    "                          running_loss/((i+1)*batch_size), 100*correct/((i+1)*batch_size), time.time()-start_time), end='\\r', flush=True)\n",
    "            last_time = time.time()\n",
    "    print(\"Samples:{}/{}\\tloss: {:.4f}\\tacc: {:2.3f}\\telapsed_time: {:.1f}s\"\\\n",
    "          .format( (i+1)*batch_size, len(train_loader.dataset),\\\n",
    "                  running_loss/((i+1)*batch_size), 100*correct/((i+1)*batch_size), time.time()-start_time), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5586)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rnn(X_test[:]).max(dim=1)[1] == y_test[:]).float().sum()/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
