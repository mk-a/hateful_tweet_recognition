{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import words_repeated_char\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file_path, delimiter = ' '):\n",
    "    \"\"\" We had some issues loading the data using pandas.read_csv, so we built our own loader.\n",
    "        Read a csv file, returns a pandas.Dataframe\n",
    "    \"\"\"\n",
    "    fp = open(file_path)\n",
    "    line = fp.readline()\n",
    "    data_dict = dict()\n",
    "    labels = line[:-1].split(delimiter)\n",
    "    line = fp.readline()\n",
    "    for label in labels:\n",
    "        data_dict[label] = []\n",
    "    while line:\n",
    "        for i, j in enumerate(line[:-1].split(delimiter)):\n",
    "            data_dict[labels[i]].append(j)\n",
    "        line = fp.readline()\n",
    "    return pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_csv(\"data/hydrated/hateful_tweets_filtered.csv\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7629505483</td>\n",
       "      <td>abusive</td>\n",
       "      <td>I fuckin hate when niggas stare at me fuck r u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>12181574836</td>\n",
       "      <td>abusive</td>\n",
       "      <td>everyone jumps to silly conclusions as soon as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>25381445793</td>\n",
       "      <td>abusive</td>\n",
       "      <td>#sincewerebeinghonest I'm Emo. I Need A Fuckin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>192730077165916160</td>\n",
       "      <td>abusive</td>\n",
       "      <td>banana bread recipe: 1. get some bread 2. i do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>280882735374028800</td>\n",
       "      <td>abusive</td>\n",
       "      <td>godamn this bitch so bad i want 2 drink molly ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id    label  \\\n",
       "0          7629505483  abusive   \n",
       "1         12181574836  abusive   \n",
       "2         25381445793  abusive   \n",
       "3  192730077165916160  abusive   \n",
       "4  280882735374028800  abusive   \n",
       "\n",
       "                                       tweet_content  \n",
       "0  I fuckin hate when niggas stare at me fuck r u...  \n",
       "1  everyone jumps to silly conclusions as soon as...  \n",
       "2  #sincewerebeinghonest I'm Emo. I Need A Fuckin...  \n",
       "3  banana bread recipe: 1. get some bread 2. i do...  \n",
       "4  godamn this bitch so bad i want 2 drink molly ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer() \n",
    "X = []\n",
    "for i, tweet in enumerate(data[\"tweet_content\"].values[:]):\n",
    "    tmp = tweet.lower().replace(\"\\\\n\",' ').replace('\\\\xa0', ' ').replace('\\\\r', ' ').replace(\"\\\\'\",\"'\").replace(\"&lt;\",'<')\\\n",
    "         .replace(\"&gt;\",'>').replace(\" &amp; \", \" and \").replace(\"&amp;\", \"&\")\n",
    "    # lower the tweet and replacing characters that tweeter has tranlated to their hmtl numeric code to their original value\n",
    "    tmp = re.sub(\"(http(s)?://)?(www\\.)?([a-zA-Z0-9])+\\.[a-z]{1,3}(/\\S*)?\",'URL', tmp) # \n",
    "    tmp = re.sub(\"#\\w+\", 'HASHTAG', tmp)\n",
    "    tmp = re.sub(\"@\\w+\", 'USER', tmp)\n",
    "    tmp = re.sub(\"\\w+@\\w+\\.[a-z]{2,3}\", \"EMAIL\", tmp)\n",
    "    tmp = re.sub(\"[0-9]{1,2}/[0-9]{1,2}/([0-9]{4}|[0-9]{2})|([0-9]{4}|[0-9]{2})/[0-9]{1,2}/[0-9]{1,2}|[0-9]{2}/[0-9]{2}\", \"DATE\", tmp)\n",
    "    tmp = re.sub(\"[0-9]{2}(:[0-9]{2}){1,2}( ?(am|pm))?\", \"TIME\", tmp)\n",
    "    tmp = re.sub(\"(([\\U00002600-\\U000027BF])|([\\U0001f300-\\U0001f64F])|([\\U0001f680-\\U0001f6FF]))+\", ' EMOJI ', tmp)\n",
    "    tmp = tmp.encode(encoding='ascii', errors='ignore').decode()\n",
    "    # get rid of the non ascii characters\n",
    "    tmp = re.sub(\"\\.{2,}\", \"...\", tmp)\n",
    "    for c in ['!', '-', ',']:\n",
    "        tmp = re.sub(\"{}+\".format(c), c, tmp)\n",
    "    tmp = re.sub(\"\\?+\", \"?\", tmp)\n",
    "    tmp = re.sub(\"`+\", \"'\", tmp)\n",
    "    tmp = re.sub(\"'{2,}\", \"'\", tmp)\n",
    "    tmp = tmp.translate(str.maketrans(dict.fromkeys('#*+/<=>@[\\\\]^_`{|}~'))) #removing all the other special characters\n",
    "    tokens = [t if t not in [\"''\", \"``\"] else '\"' for t in word_tokenize(tmp) ]\n",
    "    # tokenizing using nltk.word_tokenize. althought it transforms '\"' into '``' or \"''\" and this is a behaviour do not want\n",
    "    # so we make sure that the '\"' are changed to their original form\n",
    "    for i, token in enumerate(tokens):\n",
    "        if re.search(r\"([a-z])\\1{2,}\", token):\n",
    "            # cleaning the words containing a letter repeated 3 times or more, using the list of the Ensglish words\n",
    "            tokens[i] = words_repeated_char.clean(token)\n",
    "        tokens[i] = lemmatizer.lemmatize(tokens[i])\n",
    "    X.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(data[\"label\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
